{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "This notebook contains the solution implemented for the \"Collaboration and Competition\" project based on a Unity's ML-Agents environment. This is the third and last project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Solution description\n",
    "\n",
    "The project consist of the resolution of a multi-agent environment (two) where the Multi-Agent Deep Deterministic Policy Gradients (MADDPG) algorithm was used to solve the scenario.\n",
    "\n",
    "The MADDPG algorithm uses an actor-critic approach with centralized planning and decentralized execution. In can be used for competitive, cooperative and mixed scenarios.\n",
    "\n",
    "<p align=\"middle\"><img src=\"images\\Centralized planning-decentralized execution.png\" width=\"600\"></p>\n",
    "\n",
    "When training the critic part of the agents uses the states observed by all the agents as input (and their actions).\n",
    "\n",
    "<p align=\"middle\"><img src=\"images\\training.png\" width=\"600\"></p>\n",
    "\n",
    "During testing the actors only have access to their own observations to take actions.\n",
    "\n",
    "<p align=\"middle\"><img src=\"images\\execution.png\" width=\"600\"></p>\n",
    "\n",
    "For the code the algorithm shown in the Lesson 6 (Deep RL for Finance) has been used as reference and adapted to the MADDPG specifications. The networks and the hyperparameters have been defined from scratch and have been tuned from testing.\n",
    "\n",
    "Once the agent reach the specified goal (the average over 100 episodes of the higher score for both agents is at least +0.5), the networks for both agents are saved (with their actor and critic models) in the \"final\" directory and a graph with the scores and the running means (for a window of 100 episodes) is plotted.\n",
    "\n",
    "As indicated above, the \"final\" directory contains the weights of the final networks while the intermediate weights obtained during training are in the \"checkpoints\" directory.\n",
    "\n",
    "The project solution is comprised of this same jupyter notebook (Tennis.ipynb) and the following files:\n",
    "\n",
    "* maddpg_manager.py: Contains the \"manager\" class to manage the whole training process, here are instantiated the needed agents.\n",
    "* maddpg_agent.py: Contains the agent implementation for the MADDPG algorithm.\n",
    "* maddpg_model.py: Contains the definition of the networks for the actor and the critic.\n",
    "* maddpg_replaybuffer.py: Contains the implementation of the replay buffer.\n",
    "* utils.py: Contains utility functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training phase\n",
    "\n",
    "### 1. Importing the required packages\n",
    "\n",
    "We begin by importing some necessary packages. maddpg_agent and utils are modules developed as part of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "from maddpg_manager import MADDPGManager\n",
    "from utils import plot_scores\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting the model and training parameters \n",
    "\n",
    "Next, a series of constants are defined that will allow the model to be parameterized centrally throughout the project. This avoids having to go through different files to configure the parameters and avoids errors in the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "TRAINING_MODE = False                            # Enable or disable the graphical output\n",
    "N_EPISODES = 10000                              # Max number of episodes for the training\n",
    "MAX_T = 500                                    # Max number of steps per episode\n",
    "SCORES_WINDOW = 100                             # Size for the window of the average score\n",
    "GOAL_SCORE = 0.5                                # Target average score over 100 consecutive episodes\n",
    "\n",
    "# Environment parameters\n",
    "NUM_AGENTS = 2                                  # Number of agents playing\n",
    "STATE_SIZE = 24                                 # Size for three stacked observations per agent (8*3=24)\n",
    "ACTION_SIZE = 2                                 # Size for the action\n",
    "# CRITIC_STATE_SIZE = NUM_AGENTS * (AGENT_STATE_SIZE + ACTION_SIZE)       # Size for the critic input (2*(24+2))\n",
    "RANDOM_SEED = 777                              # Random seed\n",
    "UNITY_ENV_PATH = 'Tennis_Windows_x86_64\\Tennis.exe'         #Path for the Unity environment\n",
    "\n",
    "# Agent parameters\n",
    "BUFFER_SIZE = 100000                            # Size for the replay memory\n",
    "BATCH_SIZE = 256                                # Size for the minibatch\n",
    "GAMMA = 0.99                                       # According to the specification where won't be discount for the rewards\n",
    "TAU = 1e-3                                      # Parameter for soft update of Q_target \n",
    "# TAU = 0.002                                      # Parameter for soft update of Q_target \n",
    "# LR_ACTOR = 1e-4                               # Learning rate of the actor \n",
    "# LR_CRITIC = 1e-3                              # Learning rate of the critic\n",
    "LR_ACTOR = 1e-4                              # Learning rate of the actor \n",
    "LR_CRITIC = 1e-3                              # Learning rate of the critic\n",
    "UPDATE_FRECUENCY = 2\n",
    "# WEIGHT_DECAY = 1e-4                           # L2 weight decay\n",
    "WEIGHT_DECAY = 0.0                                # L2 weight decay\n",
    "\n",
    "# Network parameters\n",
    "HIDDEN_LAYERS = (256, 256)                       # Tuple with the sizes for the hidden layers (generated dynamically from these values)\n",
    "\n",
    "# Checkpoints parameters\n",
    "CHECKPOINTS_PATH = \"checkpoints\"                # Directory for the checkpoints of the network weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configuring where the model will run\n",
    "GPU processing is configured whenever possible, a message indicates whether the model will be trained/executed on the CPU or on the GPU using CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Starting up the environment\n",
    "\n",
    "The environment is started.  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```\n",
    "\n",
    "If TRAINING_MODE is True there won't be graphical output of the environment during training to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "if TRAINING_MODE:\n",
    "    env = UnityEnvironment(file_name = UNITY_ENV_PATH, no_graphics=True)\n",
    "else:\n",
    "    env = UnityEnvironment(file_name = UNITY_ENV_PATH)\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "Vector action description: ['', '']\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "print (f\"Vector action description: {brain.vector_action_descriptions}\")\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training the model\n",
    "\n",
    "In the next code cell we are going to train the agent in the running environment.\n",
    "\n",
    "Here the agent will run several episodes (with the maximum specified) each one with a maximum of 1000 timesteps.\n",
    "\n",
    "Once the goal is achieved the training stops and the weights for the actor and the critic networks will be saved.\n",
    "\n",
    "After this, a graph with the increasing score along the episodes will be plotted with the moving averages for 100 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.009\t Max Score: 0.100\n",
      "Episode 200\tAverage Score: 0.009\t Max Score: 0.100\n",
      "Episode 300\tAverage Score: 0.026\t Max Score: 0.100\n",
      "Episode 400\tAverage Score: 0.010\t Max Score: 0.100\n",
      "Episode 500\tAverage Score: 0.027\t Max Score: 0.190\n",
      "Episode 600\tAverage Score: 0.027\t Max Score: 0.100\n",
      "Episode 700\tAverage Score: 0.007\t Max Score: 0.100\n",
      "Episode 800\tAverage Score: 0.005\t Max Score: 0.100\n",
      "Episode 900\tAverage Score: 0.036\t Max Score: 0.300\n",
      "Episode 1000\tAverage Score: 0.051\t Max Score: 0.190\n",
      "Episode 1100\tAverage Score: 0.045\t Max Score: 0.200\n",
      "Episode 1200\tAverage Score: 0.062\t Max Score: 0.200\n",
      "Episode 1300\tAverage Score: 0.094\t Max Score: 0.300\n",
      "Episode 1400\tAverage Score: 0.119\t Max Score: 0.400\n",
      "Episode 1500\tAverage Score: 0.139\t Max Score: 0.690\n",
      "Episode 1600\tAverage Score: 0.406\t Max Score: 1.400\n",
      " Environment Solved in Episode 1627\tAverage Score: 0.508\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def maddpg(n_episodes, max_t):\n",
    "          \n",
    "    # All the agents will have the same action space\n",
    "    maddpg_manager = MADDPGManager(num_agents=NUM_AGENTS, state_size=STATE_SIZE, action_size=ACTION_SIZE, hidden_layers=HIDDEN_LAYERS, buffer_size=BUFFER_SIZE, batch_size=BATCH_SIZE, update_frequency=UPDATE_FRECUENCY, gamma=GAMMA, tau=TAU, lr_actor=LR_ACTOR, lr_critic=LR_CRITIC, weight_decay=WEIGHT_DECAY, random_seed=RANDOM_SEED)     \n",
    "    \n",
    "    scores_deque = deque(maxlen=SCORES_WINDOW)\n",
    "    scores = []\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]  \n",
    "        states = env_info.vector_observations                  # get the current observations (here are the states for all the agents) \n",
    "        \n",
    "        scorestab = np.zeros(num_agents)                   # initialize the score (for each agent)\n",
    "        rewardslist = []   \n",
    "\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            actions = maddpg_manager.act(states)      # get the actions from all the agents\n",
    "                    \n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    \n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)            \n",
    "            rewards = env_info.rewards                         # get reward (for each agent)                       \n",
    "            dones = env_info.local_done                        # see if episode finished                                                    \n",
    "                       \n",
    "            maddpg_manager.save_experience(states, actions, rewards, next_states, dones)\n",
    "            \n",
    "            scorestab += env_info.rewards            \n",
    "            rewardslist.append(rewards)\n",
    "            \n",
    "            states = next_states                               # roll over states to next time step\n",
    "            \n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break\n",
    "\n",
    "        # calculate episode reward as maximum of individually collected rewards of agents\n",
    "        episode_reward = np.max(np.sum(np.array(rewardslist),axis=0))        \n",
    "        scores.append(episode_reward)             # save most recent score to overall score array\n",
    "        scores_deque.append(episode_reward)       # save most recent score to running window of 100 last scores\n",
    "        \n",
    "        # log average score every 100 episodes        \n",
    "        if i_episode % 100 == 0:\n",
    "            print(f\"\\rEpisode {i_episode}\\tAverage Score: {np.mean(scores_deque):.3f}\\t Max Score: {np.max(scores_deque):.3f}\")\n",
    "            \n",
    "        if i_episode % 1000 == 0:            \n",
    "            maddpg_manager.save_checkpoint(path=CHECKPOINTS_PATH, is_final=False)\n",
    "            \n",
    "        if np.mean(scores_deque) >= 0.5:        # The problem is considered solved when the average over 100 episodes of the scores is at least +0.5\n",
    "            print(f\"\\r Environment Solved in Episode {i_episode}\\tAverage Score: {np.mean(scores_deque):.3f}\")\n",
    "            maddpg_manager.save_checkpoint(path=CHECKPOINTS_PATH, is_final=True)\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = maddpg(n_episodes=N_EPISODES, max_t=MAX_T)\n",
    "\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation phase\n",
    "\n",
    "The trained model will then be loaded and its performance in the Unity environment will be shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "maddpg_manager = MADDPGManager(num_agents=NUM_AGENTS, state_size=STATE_SIZE, action_size=ACTION_SIZE, hidden_layers=HIDDEN_LAYERS, buffer_size=BUFFER_SIZE, batch_size=BATCH_SIZE, update_frequency=UPDATE_FRECUENCY, gamma=GAMMA, tau=TAU, lr_actor=LR_ACTOR, lr_critic=LR_CRITIC, weight_decay=WEIGHT_DECAY, random_seed=RANDOM_SEED)       \n",
    "\n",
    "maddpg_manager.load_checkpoint(os.path.join(CHECKPOINTS_PATH,\"final\"), \"1654785585.pth\")\n",
    "\n",
    "for agent in maddpg_manager.agents:   \n",
    "    agent.actor_local.to(device)\n",
    "    agent.critic_local.to(device)\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]  \n",
    "states = env_info.vector_observations\n",
    "for t in range(500):\n",
    "    actions = maddpg_manager.act(states)               # take the actions from the agent\n",
    "    env_info = env.step(actions)[brain_name]           # send actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state\n",
    "    rewards = env_info.rewards                         # get reward\n",
    "    dones = env_info.local_done   \n",
    "    states = next_states                               # next state is the current state now\n",
    "    if np.any(dones):                                  # exit if episode finished\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusions\n",
    "\n",
    "During the training process I tried different configurations for the neural network varying both the size and the number of hidden layers.\n",
    "\n",
    "I had to increase the complexity of the hidden layers until I could verify that the agents were able to learn.\n",
    "\n",
    "Finding the right values for the learning rates of the actor and critic network was also critical for the agents to learn correctly.\n",
    "\n",
    "A mechanism has been implemented to stop applying noise to the actor's actions after a certain number of time steps, in order to improve the scores after a sufficient period of experimentation.\n",
    "\n",
    "## 5. Next steps\n",
    "\n",
    "As an exercise on the sidelines of the project, I will implement other versions of the agent that make use of the improvements seen in the nanodegree, such as:\n",
    "\n",
    "* Prioritized experience replay: it could help to improve the training performance and to reduce the required time.\n",
    "\n",
    "It seems also that agents take a long time to start learning, I have to look for techniques and improvements in the MADDPG algorithm aimed at increasing the learning slope.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5681449197eceb4dff89b8509da54eaeee8f98d133f1688c9660c267dfbc4be4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('unity4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
